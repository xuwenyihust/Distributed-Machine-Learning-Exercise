{"cells":[{"cell_type":"markdown","source":["# PastHires"],"metadata":{}},{"cell_type":"markdown","source":["### Import libraries"],"metadata":{}},{"cell_type":"code","source":["from pyspark.mllib.regression import LabeledPoint\nfrom pyspark.mllib.tree import DecisionTree\nfrom pyspark import SparkConf, SparkContext\nfrom numpy import array\nimport requests"],"metadata":{},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":["### Load Data\n\nLoad the data from DBFS and filter out the header line."],"metadata":{}},{"cell_type":"code","source":["rawData = sc.textFile(\"/FileStore/tables/0xwtlnmf1469416481691/PastHires.csv\")\nprint 'Raw data:' \nprint rawData.take(5)\nheader = rawData.first()\nrawData = rawData.filter(lambda x:x != header)\nprint 'Filtered raw data:'\nprint rawData.take(5)"],"metadata":{},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":["### Data Cleaning\n\nWe can see that each line is a string containing values separated by commas.\n\nSplit each line into a list.\n\nUse **map()** to apply the split() function to every value in the RDD"],"metadata":{}},{"cell_type":"code","source":["csvData = rawData.map(lambda x: x.split(\",\"))"],"metadata":{},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":["Convert the lists into **LabelPoints**,\n\nin order to create the **training data set**, and convert non-numerical features into **numerical features**."],"metadata":{}},{"cell_type":"code","source":["# Convert 'Y'/'N' into numerical features 1/0\ndef binary(YN):\n    if (YN == 'Y'):\n        return 1\n    else:\n        return 0\n      \n# Convert 'BS'/'MS'/'PhD' into 1/2/3\ndef mapEducation(degree):\n    if (degree == 'BS'):\n        return 1\n    elif (degree =='MS'):\n        return 2\n    elif (degree == 'PhD'):\n        return 3\n    else:\n        return 0\n\ndef createLabeledPoints(fields):\n    yearsExperience = int(fields[0])\n    employed = binary(fields[1])\n    previousEmployers = int(fields[2])\n    educationLevel = mapEducation(fields[3])\n    topTier = binary(fields[4])\n    interned = binary(fields[5])\n    hired = binary(fields[6])\n\n    return LabeledPoint(hired, array([yearsExperience, employed, previousEmployers, educationLevel, topTier, interned]))"],"metadata":{},"outputs":[],"execution_count":9},{"cell_type":"code","source":["trainingData = csvData.map(createLabeledPoints)"],"metadata":{},"outputs":[],"execution_count":10},{"cell_type":"markdown","source":["Construct a **DecisionTree** model and train it."],"metadata":{}},{"cell_type":"code","source":["model = DecisionTree.trainClassifier(trainingData, numClasses=2,\n                                     categoricalFeaturesInfo={1:2, 3:4, 4:2, 5:2},\n                                     impurity='gini', maxDepth=5, maxBins=32)"],"metadata":{},"outputs":[],"execution_count":12},{"cell_type":"markdown","source":["Create a fake dataset."],"metadata":{}},{"cell_type":"code","source":["testCandidates = [ array([10, 1, 3, 1, 0, 0])]\ntestData = sc.parallelize(testCandidates)"],"metadata":{},"outputs":[],"execution_count":14},{"cell_type":"markdown","source":["Predict."],"metadata":{}},{"cell_type":"code","source":["prediction = model.predict(testData).collect()\nprint prediction"],"metadata":{},"outputs":[],"execution_count":16},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":17}],"metadata":{"name":"past_hires","notebookId":4358146023355663},"nbformat":4,"nbformat_minor":0}
