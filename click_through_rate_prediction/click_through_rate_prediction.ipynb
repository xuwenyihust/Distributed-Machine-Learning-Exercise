{"cells":[{"cell_type":"markdown","source":["# Click-Through Rate Prediction\n### Notebook created by [Wenyi Xu](https://github.com/xuwenyihust)\n### Create a [click-through rate](https://www.kaggle.com/c/criteo-display-ad-challenge) (CTR) prediction pipeline."],"metadata":{}},{"cell_type":"code","source":["import numpy as np\nfrom pyspark.mllib.linalg import SparseVector"],"metadata":{},"outputs":[],"execution_count":2},{"cell_type":"markdown","source":["### 1. Parse CTR Data\n\nView Criteo's agreement."],"metadata":{}},{"cell_type":"code","source":["from IPython.lib.display import IFrame\n\nIFrame(\"http://labs.criteo.com/downloads/2014-kaggle-display-advertising-challenge-dataset/\", 600, 350)"],"metadata":{},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":["#### Load the data"],"metadata":{}},{"cell_type":"code","source":["# Hidden path\nrawData = sc.textFile('/FileStore/tables/86sw321e1469469485636/dac_sample.txt').map(lambda x: x.replace('\\t', ','))\nprint rawData.take(1)\nprint type(rawData)"],"metadata":{},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":["#### Split the dataset into training, validation and test sets\n\nSpecify the weights & seed for randomSplit method.\n\n**Training : Validation : Test** will be **8 : 1 : 1**."],"metadata":{}},{"cell_type":"code","source":["weights = [.8, .1, .1]\nseed = 42"],"metadata":{},"outputs":[],"execution_count":8},{"cell_type":"code","source":["rawTrainData, rawValidationData, rawTestData = rawData.randomSplit(weights, seed)"],"metadata":{},"outputs":[],"execution_count":9},{"cell_type":"markdown","source":["**Cache** the splitted datasets, since we will be repeatedly using them."],"metadata":{}},{"cell_type":"code","source":["rawTrainData.cache()\nrawValidationData.cache()\nrawTestData.cache()"],"metadata":{},"outputs":[],"execution_count":11},{"cell_type":"markdown","source":["**Data preview**."],"metadata":{}},{"cell_type":"code","source":["nTrain = rawTrainData.count()\nnVal = rawValidationData.count()\nnTest = rawTestData.count()\nprint nTrain, nVal, nTest, nTrain + nVal + nTest\nprint rawData.take(1)"],"metadata":{},"outputs":[],"execution_count":13},{"cell_type":"markdown","source":["#### Extract features\n\nSplit each datapoint of type string into different field.\n\nDrop the first field -> **label** (clicked or not)\n\nSave the remaining fields -> **features**"],"metadata":{}},{"cell_type":"markdown","source":["Define a *parse_data_point* function, input each data point(row), return a list of **(featureID, value)** tuples."],"metadata":{}},{"cell_type":"code","source":["def parsePoint(point):\n    \"\"\"Converts a comma separated string into a list of (featureID, value) tuples.\n\n    Note:\n        featureIDs should start at 0 and increase to the number of features - 1.\n\n    Args:\n        point (str): A comma separated string where the first value is the label and the rest\n            are features.\n\n    Returns:\n        list: A list of (featureID, value) tuples.\n    \"\"\"\n    features = point.split(',')[1:]\n    return [(idx, value) for (idx, value) in enumerate(features)]"],"metadata":{},"outputs":[],"execution_count":16},{"cell_type":"code","source":["parsedTrainFeat = rawTrainData.map(parsePoint)\nprint parsedTrainFeat.take(1)"],"metadata":{},"outputs":[],"execution_count":17},{"cell_type":"markdown","source":["We can see that now the string of features has been splitted into a list of features.\n\nCount the **number of distinct values for each feature**."],"metadata":{}},{"cell_type":"code","source":["numCategories = (parsedTrainFeat\n                 # Flatten all the elements in the list\n                 .flatMap(lambda x: x)\n                 # Drop the duplicated values for features\n                 .distinct()\n                 # Set feature value to 1 for the convenience of counting\n                 .map(lambda x: (x[0], 1))\n                 # Count how many times each key (featureID) occurs\n                 .reduceByKey(lambda x, y: x + y)\n                 .sortByKey()\n                 .collect())\n\nprint numCategories[2][1]"],"metadata":{},"outputs":[],"execution_count":19},{"cell_type":"markdown","source":["### 2. Generate OHE Features"],"metadata":{}},{"cell_type":"markdown","source":["#### Construct an OHE dictionary\n\nCategorical feature:  **(featureID, category)** tuple.\n\nOHE dictionary:  **Map** each tuple **to** a distinct **integer**.\n\nFunction:\n\n- Input the lists of (featureID, category) tuples.\n- Flatten the lists to get all the unique (featureID, category) tuples.\n- Attach a unique integer to each distinct feature to create the dictionary."],"metadata":{}},{"cell_type":"code","source":["def createOneHotDict(inputData):\n    \"\"\"Creates a one-hot-encoder dictionary based on the input data.\n\n    Args:\n        inputData (RDD of lists of (int, str)): An RDD of observations where each observation is\n            made up of a list of (featureID, value) tuples.\n\n    Returns:\n        dict: A dictionary where the keys are (featureID, value) tuples and map to values that are\n            unique integers.\n    \"\"\"\n    distinctFeats = (inputData\n                       .flatMap(lambda row: row)\n                       .distinct())\n    \n    return (distinctFeats\n                           # Zips this RDD with its element indices\n                           # (featureID, value) -> ((featureID, value), int)\n                           .zipWithIndex()\n                           # Return the key-value pairs in this RDD to the master as a dictionary.\n                           .collectAsMap())"],"metadata":{},"outputs":[],"execution_count":22},{"cell_type":"markdown","source":["Create a **OHE dictionary** based on the **parsedTrainFeat**:\n\n    [[(0, u'1'), (1, u'1'), (2, u'5'), (3, u'0'), (4, u'1382'), (5, u'4'), (6, u'15'), ..."],"metadata":{}},{"cell_type":"code","source":["ctrOHEDict = createOneHotDict(parsedTrainFeat)\nnumCtrOHEFeats = len(ctrOHEDict.keys())\nprint 'Number of elements in the dictionary: ', numCtrOHEFeats"],"metadata":{},"outputs":[],"execution_count":24},{"cell_type":"code","source":["print \"(0, '1'): \", ctrOHEDict[(0, '1')]\nprint \"(0, '3'): \", ctrOHEDict[(0, '3')]\nprint \"(1, '4'): \", ctrOHEDict[(1, '4')]\nprint \"(3, '1'): \", ctrOHEDict[(3, '1')]\nprint \"(9, '3'): \", ctrOHEDict[(9, '3')]"],"metadata":{},"outputs":[],"execution_count":25},{"cell_type":"markdown","source":["#### Define a OHE function\n\nUse it to generate **OHE features** from the original categorical data.\n\nThe OHE features should be **SparseVector** format to reduce the storage & computational burdens."],"metadata":{}},{"cell_type":"code","source":["def oneHotEncoding(rawFeats, OHEDict, numOHEFeats):\n    \"\"\"Produce a one-hot-encoding from a list of features and an OHE dictionary.\n\n    Note:\n        You should ensure that the indices used to create a SparseVector are sorted.\n\n    Args:\n        rawFeats (list of (int, str)): The features corresponding to a single observation.  Each\n            feature consists of a tuple of featureID and the feature's value. (e.g. sampleOne)\n        OHEDict (dict): A mapping of (featureID, value) to unique integer.\n        numOHEFeats (int): The total number of unique OHE features (combinations of featureID and\n            value).\n\n    Returns:\n        SparseVector: A SparseVector of length numOHEFeats with indicies equal to the unique\n            identifiers for the (featureID, value) combinations that occur in the observation and\n            with values equal to 1.0.\n    \"\"\"\n    return SparseVector(numOHEFeats, [(OHEDict[(featID, value)],1) for (featID, value) in rawFeats])"],"metadata":{},"outputs":[],"execution_count":27},{"cell_type":"markdown","source":["#### Apply OHE to the dataset\n\nFor each data point (sample):\n\n**data point -> one-hot encoded (categorical to numerical) -> sparse vector -> labeled point**"],"metadata":{}},{"cell_type":"code","source":["from pyspark.mllib.regression import LabeledPoint"],"metadata":{},"outputs":[],"execution_count":29},{"cell_type":"code","source":["def parseOHEPoint(point, OHEDict, numOHEFeats):\n    \"\"\"Obtain the label and feature vector for this raw observation.\n\n    Note:\n        You must use the function `oneHotEncoding` in this implementation or later portions\n        of this lab may not function as expected.\n\n    Args:\n        point (str): A comma separated string where the first value is the label and the rest\n            are features.\n        OHEDict (dict of (int, str) to int): Mapping of (featureID, value) to unique integer.\n        numOHEFeats (int): The number of unique features in the training dataset.\n\n    Returns:\n        LabeledPoint: Contains the label for the observation and the one-hot-encoding of the\n            raw features based on the provided OHE dictionary.\n    \"\"\"\n    return LabeledPoint(point.split(',')[0],oneHotEncoding(parsePoint(point), OHEDict, numCtrOHEFeats))"],"metadata":{},"outputs":[],"execution_count":30},{"cell_type":"code","source":["OHETrainData = rawTrainData.map(lambda point: parseOHEPoint(point, ctrOHEDict, numCtrOHEFeats))\nOHETrainData.cache()\nprint OHETrainData.take(1)"],"metadata":{},"outputs":[],"execution_count":31},{"cell_type":"markdown","source":["To explain the format of the resulting data points:"],"metadata":{}},{"cell_type":"code","source":["SparseVector(10, [(1,1), (6,1)])"],"metadata":{},"outputs":[],"execution_count":33},{"cell_type":"code","source":["LabeledPoint(0, SparseVector(10, [(1,1), (6,1)]))"],"metadata":{},"outputs":[],"execution_count":34},{"cell_type":"markdown","source":["### Visualize the Feature Frequency"],"metadata":{}},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":36},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":37}],"metadata":{"name":"click_through_rate_prediction","notebookId":2004297364207044},"nbformat":4,"nbformat_minor":0}
